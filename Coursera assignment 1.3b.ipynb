{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subject is quite heavy on mathematics, so it's going to be a bit hard to explain to a high school graduate, but I'm going to try anyway :)\n",
    "\n",
    "In the field of machine learning, which is about programming computers to answer certain questions about data, deep learning is the study of algorithms based on deep (or hierarchical) neural networks. Deep neural networks are built out of a series of layers that are composed in various \"architectures\", and can be trained on data like other machine learning algorithms. They can be used to answer inference questions (predict a new output value based on an input set of features) and classification (assign a class to an input), and trained in supervised or unsupervised fashion. \n",
    "\n",
    "The most challenging part of the course was interestingly enough the first two weeks, which were about gradient descent and back propagation. Statistical inference is about using a set of data to learn a number of parameters. These parameters are then used to answer questions about new datapoints. A very common technique is called linear regression. Given a set of 2-dimensional input data, for example the size of appartments, and their price, we fit a simple line to the data. We can then look up an approximate price for arbitrary appartment size. This is shown in the image below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Linear regression](img/linear-regression.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In this case, we use the data points to learn the parameters for a function a * x + b. The better we chose a and b, the better we can fit our function to the data, and the better predictions we can make. We measure how good our model fits the data by using a loss function. The loss function is a function of the training data, and of the model parameters. In our case, the inputs to the loss function would be a, b and the training data. A commonly used loss function is the mean squared error. For every data point, we compute what the model would have predicted, and sum the square of the error. The higher the mean squared error, the worst our model is. \n",
    "\n",
    "![Mean squared error](img/mean-squared-error.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In order to find the best possible model, we want to minimize this loss function. We want to find the set of parameters theta such that the loss function is the smallest. This is called an optimization problem, and it is a very important part of mathematics. A very common approach is called gradient descent. You compute the gradient of your loss function according to your model parameters, and follow it in the inverse direction. The gradient of a function is the direction in which the function gets bigger the quickest. In the one-dimensional case (for example for our appartment size linear regression), the gradient is the derivative of the function.\n",
    "\n",
    "![1D gradient](img/1d-gradient-descent2.jpg)\n",
    "\n",
    " In the two dimensional case, we have a 2D vector, and so on.\n",
    " \n",
    " ![2D gradient](img/2d-gradient.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach for gradient descent is to start with a certain estimation of our parameters w0. We compute the gradient of the function at w0, and use that to update our current estimation to get w1. For that, we subtract a fraction of the gradient. This fraction is called the learning rate. We don't want to shoot around the solution space like a maniac, but we also don't want to crawl like a snail. Once we reach a satisfying solution, we stop searching for better parameters. The following image shows a possible trajectory in 2D space.\n",
    "\n",
    "![2D gradient descent example](img/2d-gradient-descent-example.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This leaves a fair amount of parameters to be determined:\n",
    "\n",
    "* What is our initial starting point w0?\n",
    "* How do we compute our learning rate?\n",
    "* When do we stop?\n",
    "* Is there a better to compute the loss function?\n",
    "\n",
    "These questions are answered all along the course, but they are also still very important open research topics.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
